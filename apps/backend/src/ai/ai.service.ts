// apps/backend/src/ai/ai.service.ts
import { Injectable } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import { BaseChatModel } from '@langchain/core/language_models/chat_models';
import { ChatGoogleGenerativeAI } from '@langchain/google-genai';
import { ChatOpenAI } from '@langchain/openai'; // é¢„å…ˆå¼•å…¥ï¼Œæ–¹ä¾¿æœªæ¥åˆ‡æ¢

// å®šä¹‰æ”¯æŒçš„ AIä¾›åº”å•†ç±»å‹ï¼Œæ–¹ä¾¿æ‰©å±•
export type AIProvider = 'gemini' | 'openai';

@Injectable()
export class AIService {
  constructor(private configService: ConfigService) {}

  /**
   * æ ¹æ®ä¾›åº”å•†è·å–ä¸€ä¸ªæ”¯æŒæµå¼çš„èŠå¤©æ¨¡å‹å®ä¾‹
   * @param provider AI ä¾›åº”å•†
   * @returns ä¸€ä¸ªå®ç°äº† BaseChatModel çš„å®ä¾‹
   */
  getStreamingModel(provider: AIProvider): BaseChatModel {
    switch (provider) {
      case 'gemini':
        console.log('ğŸš€ ~ Using Gemini model');
        return new ChatGoogleGenerativeAI({
          apiKey: this.configService.get<string>('GEMINI_API_KEY'),
          modelName: 'gemini-1.5-pro-latest',
          streaming: true,
        });

      case 'openai':
        console.log('ğŸš€ ~ Using OpenAI model');
        return new ChatOpenAI({
          apiKey: this.configService.get<string>('OPENAI_API_KEY'),
          modelName: 'gpt-4-turbo-preview',
          streaming: true,
        });

      default:
        throw new Error(`Unsupported AI provider: ${provider as string}`);
    }
  }
}
